{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess functions\n",
    "from basic_functions import cust_dummies, custom_preprocess\n",
    "from basic_functions import get_data_from_csv, feature_engineering, tts_custom, custom_smote\n",
    "from basic_functions import custom_logreg, custom_knn, custom_nb, custom_svc, custom_rf, custom_stack\n",
    "# for some reason the other functions won't load\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data_from_csv()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts_custom(df, RSEED = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = custom_smote(X_train, y_train, 42)\n",
    "\n",
    "# sort test to match train\n",
    "X_test = X_test[[\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\", \n",
    "        \"weekday\", \"difference\", \"InOut\", \"Value\", \"time_of_day\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# andrey and john: how are transactions \"developing\" within an Id\n",
    "# number of customer ids associated with an account\n",
    "# starting a grid search\n",
    "# making sure functions are documented and everything is pushed to git hub\n",
    "# Jannik: check the pattern?\n",
    "# feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    \"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\", \"InOut\", \"difference\", \"weekday\"\n",
    "    ]\n",
    "num_features = [\"Value\", \"time_of_day\"]\n",
    "\n",
    "X_train_sm_sc, X_test_sc = custom_preprocess(X_train_sm, X_test, nf=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure types are the same for train and test (can certainly be done more elegantly from the start)\n",
    "X_test_sc = X_test_sc.astype({\"difference\": \"object\", \"InOut\": \"object\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm_sc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm_sc, cat_features_dummies = cust_dummies(X_train_sm_sc, cat_features)\n",
    "X_test_sc, cat_features = cust_dummies(X_test_sc, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm_lr, y_test_lr = custom_logreg(X_train_sm_sc, X_test_sc, y_train_sm, y_test)\n",
    "confusion_matrix(y_test, y_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm_nb, y_test_nb = custom_nb(X_train_sm_sc, X_test_sc, y_train_sm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_test_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm_rf, y_test_rf = custom_rf(X_train_sm_sc, X_test_sc, y_train_sm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm_knn, y_test_knn = custom_knn(X_train_sm_sc, X_test_sc, y_train_sm, y_test)\n",
    "confusion_matrix(y_test, y_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm_svc, y_test_svc = custom_svc(X_train_sm_sc, X_test_sc, y_train_sm, y_test)\n",
    "confusion_matrix(y_test, y_test_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm_stack, y_test_stack = custom_knn(X_train_sm_sc, X_test_sc, y_train_sm, y_test)\n",
    "confusion_matrix(y_test, y_test_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "###########################\n",
    "#  Predict on test data   #\n",
    "###########################\n",
    "\n",
    "# Calculating the accuracy for the LogisticRegression Classifier \n",
    "print('Cross validation scores Logistic Regression:')\n",
    "print('-------------------------')\n",
    "print(\"F1-score: {:.2f}\".format(f1_score(y_test, y_test_lr)))\n",
    "print(\"MCC: {:.2f}\".format(matthews_corrcoef(y_test, y_test_lr)))\n",
    "\n",
    "# Calculating the accuracy for the RandomForest Classifier \n",
    "print('Cross validation scores Random Forest:')\n",
    "print('-------------------------')\n",
    "print(\"F1-score: {:.2f}\".format(f1_score(y_test, y_test_rf)))\n",
    "print(\"MCC: {:.2f}\".format(matthews_corrcoef(y_test, y_test_rf)))\n",
    "\n",
    "# Calculating the accuracy for the KNN Classifier \n",
    "print('Cross validation scores KNN:')\n",
    "print('-------------------------')\n",
    "print(\"F1-score: {:.2f}\".format(f1_score(y_test, y_test_knn)))\n",
    "print(\"MCC: {:.2f}\".format(matthews_corrcoef(y_test, y_test_knn)))\n",
    "\n",
    "# Calculating the accuracy for the SVM Classifier \n",
    "print('Cross validation scores SVM:')\n",
    "print('-------------------------')\n",
    "print(\"F1-score: {:.2f}\".format(f1_score(y_test, y_test_svc)))\n",
    "print(\"MCC: {:.2f}\".format(matthews_corrcoef(y_test, y_test_svc)))\n",
    "\n",
    "# Calculating the accuracy for the Naive Bayes Classifier \n",
    "print('Cross validation scores Naive Bayes:')\n",
    "print('-------------------------')\n",
    "print(\"F1-score: {:.2f}\".format(f1_score(y_test, y_test_nb)))\n",
    "print(\"MCC: {:.2f}\".format(matthews_corrcoef(y_test, y_test_nb)))\n",
    "\n",
    "# Calculating the accuracy for the stacking Classifier \n",
    "print('Cross validation scores Stack:')\n",
    "print('-------------------------')\n",
    "print(\"F1-score: {:.2f}\".format(f1_score(y_test, y_test_stack)))\n",
    "print(\"MCC: {:.2f}\".format(matthews_corrcoef(y_test, y_test_stack)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some old code which I may want to reactivate again\n",
    "\n",
    "`# Initiate OneHotEncoder()  \n",
    "ohe = OneHotEncoder(handle_unknown='ignore')  \n",
    "# run ohe  \n",
    "X_train = ohe.fit_transform(X_train[cf])\n",
    "X_test[cf] = ohe.transform(X_test[cf])\n",
    "    \n",
    "# transfrom sparse to dense\n",
    "X_train = X_train.todense() \n",
    "X_test = X_test.todense()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As learning a model takes a lot of time, I think it would be useful to save them to file so that they can be loaded later on for prediction\n",
    "#### examplecode, save the model to disk\n",
    "from [here](https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/)  \n",
    "\n",
    "`filename = 'finalized_model.sav'  \n",
    "\n",
    "joblib.dump(model, filename)`  \n",
    " \n",
    "#### some time later...\n",
    " \n",
    "#### load the model from disk\n",
    "\n",
    "`loaded_model = joblib.load(filename)  \n",
    "\n",
    "result = loaded_model.score(X_test, Y_test)  \n",
    "\n",
    "print(result)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_from_csv():\n",
    "    \"\"\"df import with some alterations we discovered so far\n",
    "    Parses dates, drops 'CountryCode' and 'CurrencyCode' columns, sets appropriate dtypes.\n",
    "    Returns:\n",
    "        DataFrame: A dataframe with the imported data\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    return pd.read_csv(\n",
    "        'data/xente/training.csv', parse_dates=['TransactionStartTime'],  \n",
    "        index_col='TransactionId')\n",
    "import pandas as pd\n",
    "tmpdf = get_all_data_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmpdf[\"mvg_avg_fr\"] = df.FraudResult.rolling(14).mean()\n",
    "tmpdf[\"mvg_avg_v\"] = df.Value.rolling(14).mean()\n",
    "import seaborn as sns\n",
    "\n",
    "#sns.barplot(data=tmpdf, x=\"Start\")\n",
    "#tmpdf[\"day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.scatterplot(data=tmpdf, x=\"TransactionStartTime\", y=\"mvg_avg_v\", hue = \"FraudResult\")\n",
    "plt.xticks(rotation = 45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=tmpdf, x=\"TransactionStartTime\", y=\"mvg_avg_fr\", hue = \"FraudResult\")\n",
    "plt.xticks(rotation = 45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=tmpdf, x=\"TransactionStartTime\", bins=13)\n",
    "plt.xticks(rotation = 45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf.TransactionStartTime.dt.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf = get_all_data_from_csv()\n",
    "\n",
    "import numpy as np\n",
    "tmp = tmpdf[tmpdf['AccountId'].isin(list(tmpdf[tmpdf.FraudResult == 1].AccountId))].reset_index()\n",
    "\n",
    "sel = np.array(tmp[tmp[\"FraudResult\"] == 1].index)\n",
    "sel1 = sel + 1\n",
    "sel2 = sel + 2\n",
    "sel3= sel + 3\n",
    "sel4 = sel + 4\n",
    "sel01 = sel -1\n",
    "sel02 = sel -2\n",
    "sel03 = sel -3\n",
    "sel04 = sel -4\n",
    "selfinal = np.array([sel04, sel03, sel02, sel01, sel, sel1, sel2, sel3, sel4]).reshape(-1).tolist()\n",
    "tmp = tmp.iloc[sorted(selfinal), ]\n",
    "# TODO: group number of CustomerIds for each account and assign new column\n",
    "tmp.to_csv(\"data/xente/frauds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf.groupby(\"AccountId\")[\"CustomerId\"].count().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.groupby(\"AccountId\")[\"CustomerId\"].count().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8721f829b62e76f494600e5849ab226a0bc266f8f100abf162fe8bebd2c0448f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
